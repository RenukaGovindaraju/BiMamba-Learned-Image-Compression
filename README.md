Bi-Mamba: Efficient Bi-Directional State Space Models for Learned Image Compression

![Python](https://img.shields.io/badge/Python-3.10-blue) 

![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red) 

![License](https://img.shields.io/badge/License-MIT-green)

ğŸ“Œ Abstract

JPEG

BallÃ©2018

Cheng2020

Particularly strong performance is observed at bitrates below 0.5 bpp.

ğŸ“ˆ Rate-Distortion Curves

Kodak RD Curve

Tecnick RD Curve

ğŸ“ Repository Structure

model.py # Core BiMamba architecture

train1.py # Training pipeline

test_final_proposed_safe.py # Evaluation script

abla_final.py # Ablation study

phd_work2_final/ â”‚â”€â”€ Average_Results.csv â”‚â”€â”€ Detailed_Results.csv â”‚â”€â”€ Kodak/ â”‚â”€â”€ Tecnick/

âš™ï¸ Installation

conda create -n bimamba python=3.10

conda activate bimamba

pip install torch torchvision numpy matplotlib pandas tqdm
â–¶ï¸ Training

python train1.py

ğŸ§ª Evaluation

python test_final_proposed_safe.py

ğŸ§  Model Overview

The proposed BiMamba architecture consists of:

Hierarchical encoder with bidirectional State Space layers

Multi-scale latent representation

Hyperprior-based entropy modeling

Context-adaptive probability estimation

Rate-distortion optimized training objective

The architecture achieves global spatial awareness while maintaining linear computational complexity O(n).
ğŸ“„ Citation

If you use this work in your research, please cite:

@article{bimamba2026,

title={Bi-Mamba: Efficient Bi-Directional State Space Models for Learned Image Compression},

author={Renuka Govindaraju and S. Vidhusha},

year={2026} }
License

This project is released under the MIT License.
ğŸ‘©â€ğŸ”¬ Authors

Renuka Govindaraju

S. Vidhusha
